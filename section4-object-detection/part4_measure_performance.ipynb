{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Measurement using FiftyOne\n",
    "===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pyml/anaconda3/envs/objrecognition/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import fiftyone as fo\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster-RCNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = \"results/faster_rcnn\"\n",
    "\n",
    "label2idx = {\n",
    "    \"person\": 1, \"car\": 2, \"bicycle\": 3,\n",
    "    \"motorcycle\": 4, \"bus\": 5, \"truck\": 6,\n",
    "}\n",
    "\n",
    "ds_name = \"faster_rcnn_predictions\"\n",
    "if ds_name in fo.list_datasets():\n",
    "    fo.delete_dataset(ds_name)\n",
    "\n",
    "dataset = fo.Dataset(name=ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samples_count': 2968,\n",
       " 'samples_bytes': 19199380,\n",
       " 'samples_size': '18.3MB',\n",
       " 'total_bytes': 19199380,\n",
       " 'total_size': '18.3MB'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df_test = df[df[\"tag\"] == \"test\"]\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    sample = fo.Sample(filepath=row[\"imagepath\"])\n",
    "\n",
    "    filename = os.path.basename(row[\"imagepath\"])\n",
    "    img = Image.open(row[\"imagepath\"])\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    gt_file = row[\"labelpath\"]\n",
    "    with open(gt_file, \"rt\") as f:\n",
    "        gt = json.load(f)\n",
    "\n",
    "    # Add ground truth\n",
    "    list_gt = []\n",
    "    for obj in gt:\n",
    "        label = obj[\"label\"]\n",
    "        box = [\n",
    "            obj[\"x\"] / img_width, obj[\"y\"] / img_height,\n",
    "            obj[\"width\"] / img_width, obj[\"height\"] / img_height\n",
    "        ]\n",
    "        detection = fo.Detection(\n",
    "            label=label,\n",
    "            bounding_box=box\n",
    "        )\n",
    "        list_gt.append(detection)\n",
    "    sample[\"ground_truth\"] = fo.Detections(detections=list_gt)\n",
    "\n",
    "    # Add predictions\n",
    "    pred_file = os.path.join(res_dir, filename.replace(\".jpg\", \".json\"))\n",
    "    pred = json.load(open(pred_file, \"rt\"))\n",
    "\n",
    "    labels = pred[\"labels\"]\n",
    "    boxes_xyxy = pred[\"boxes_xyxy\"]\n",
    "    scores = pred[\"scores\"]\n",
    "    # convert box format from xyxy to xywh\n",
    "    boxes_xywh = torchvision.ops.box_convert(\n",
    "        torch.tensor(boxes_xyxy),\n",
    "        in_fmt=\"xyxy\",\n",
    "        out_fmt=\"xywh\"\n",
    "    )\n",
    "\n",
    "    list_detections = []\n",
    "    for label, box, score in zip(labels, boxes_xywh, scores):\n",
    "        box = [\n",
    "            box[0] / img_width, box[1] / img_height,\n",
    "            box[2] / img_width, box[3] / img_height\n",
    "        ]\n",
    "        label = list(label2idx.keys())[list(label2idx.values()).index(label)]\n",
    "        detection = fo.Detection(label=label, bounding_box=box, confidence=score)\n",
    "        list_detections.append(detection)\n",
    "\n",
    "    sample[\"faster_rcnn\"] = fo.Detections(detections=list_detections)\n",
    "    dataset.add_sample(sample)\n",
    "\n",
    "dataset.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to FiftyOne on port 5151 at localhost.\n",
      "If you are not connecting to a remote session, you may need to start a new session and specify a port\n",
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset:          faster_rcnn_predictions\n",
       "Media type:       image\n",
       "Num samples:      2968\n",
       "Selected samples: 0\n",
       "Selected labels:  0\n",
       "Session URL:      http://localhost:5151/\n",
       "View stages:\n",
       "    1. FilterLabels(field='faster_rcnn', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only contains detections with confidence >= 0.75\n",
    "high_conf_view = dataset.filter_labels(\n",
    "    \"faster_rcnn\", F(\"confidence\") > 0.75, only_matches=False\n",
    ")\n",
    "\n",
    "session = fo.launch_app(high_conf_view, auto=False)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████| 2968/2968 [15.9s elapsed, 0s remaining, 199.7 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 2968/2968 [10.0s elapsed, 0s remaining, 324.3 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "results = high_conf_view.evaluate_detections(\n",
    "    \"faster_rcnn\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      person       0.68      0.67      0.67     11004\n",
      "         car       0.75      0.40      0.52      1932\n",
      "     bicycle       0.73      0.19      0.31       316\n",
      "  motorcycle       0.95      0.19      0.31       371\n",
      "         bus       0.75      0.55      0.63       285\n",
      "       truck       0.69      0.12      0.21       415\n",
      "\n",
      "   micro avg       0.68      0.60      0.64     14323\n",
      "   macro avg       0.76      0.35      0.44     14323\n",
      "weighted avg       0.70      0.60      0.62     14323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "if len(label2idx) > 10:\n",
    "    counts = dataset.count_values(\"ground_truth.detections.label\")\n",
    "    classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "else:\n",
    "    classes_top10 = list(label2idx.keys())\n",
    "    \n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv8 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = \"results/yolov8\"\n",
    "\n",
    "# for yolo, labels start from 0\n",
    "label2idx = {\n",
    "    \"person\": 0, \"car\": 1, \"bicycle\": 2,\n",
    "    \"motorcycle\": 3, \"bus\": 4, \"truck\": 5\n",
    "}\n",
    "\n",
    "ds_name = \"yolo_predictions\"\n",
    "if ds_name in fo.list_datasets():\n",
    "    fo.delete_dataset(ds_name)\n",
    "\n",
    "dataset = fo.Dataset(name=ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samples_count': 2968,\n",
       " 'samples_bytes': 4922858,\n",
       " 'samples_size': '4.7MB',\n",
       " 'total_bytes': 4922858,\n",
       " 'total_size': '4.7MB'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df_test = df[df[\"tag\"] == \"test\"]\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    sample = fo.Sample(filepath=row[\"imagepath\"])\n",
    "\n",
    "    filename = os.path.basename(row[\"imagepath\"])\n",
    "    img = Image.open(row[\"imagepath\"])\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    gt_file = row[\"labelpath\"]\n",
    "    with open(gt_file, \"rt\") as f:\n",
    "        gt = json.load(f)\n",
    "\n",
    "    # Add ground truth\n",
    "    list_gt = []\n",
    "    for obj in gt:\n",
    "        label = obj[\"label\"]\n",
    "        box = [\n",
    "            obj[\"x\"] / img_width, obj[\"y\"] / img_height,\n",
    "            obj[\"width\"] / img_width, obj[\"height\"] / img_height\n",
    "        ]\n",
    "        detection = fo.Detection(\n",
    "            label=label,\n",
    "            bounding_box=box\n",
    "        )\n",
    "        list_gt.append(detection)\n",
    "    sample[\"ground_truth\"] = fo.Detections(detections=list_gt)\n",
    "\n",
    "    # Add predictions\n",
    "    pred_file = os.path.join(res_dir, filename.replace(\".jpg\", \".json\"))\n",
    "    pred = json.load(open(pred_file, \"rt\"))\n",
    "\n",
    "    labels = pred[\"labels\"]\n",
    "    boxes_xywhn = pred[\"boxes_xywhn\"]\n",
    "    scores = pred[\"scores\"]\n",
    "\n",
    "    list_detections = []\n",
    "    for label, box, score in zip(labels, boxes_xywhn, scores):\n",
    "        box = [box[0], box[1], box[2], box[3]]\n",
    "        label = list(label2idx.keys())[list(label2idx.values()).index(label)]\n",
    "        detection = fo.Detection(label=label, bounding_box=box, confidence=score)\n",
    "        list_detections.append(detection)\n",
    "\n",
    "    sample[\"yolov8\"] = fo.Detections(detections=list_detections)\n",
    "    dataset.add_sample(sample)\n",
    "\n",
    "\n",
    "dataset.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset:          yolo_predictions\n",
       "Media type:       image\n",
       "Num samples:      2968\n",
       "Selected samples: 0\n",
       "Selected labels:  0\n",
       "Session URL:      http://localhost:5151/\n",
       "View stages:\n",
       "    1. FilterLabels(field='yolov8', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only contains detections with confidence >= 0.75\n",
    "high_conf_view = dataset.filter_labels(\n",
    "    \"yolov8\", F(\"confidence\") > 0.75, only_matches=False\n",
    ")\n",
    "\n",
    "session = fo.launch_app(high_conf_view, auto=False)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████| 2968/2968 [9.9s elapsed, 0s remaining, 336.2 samples/s]       \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 2968/2968 [9.0s elapsed, 0s remaining, 361.5 samples/s]       \n"
     ]
    }
   ],
   "source": [
    "results = dataset.evaluate_detections(\n",
    "    \"yolov8\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      person       0.41      0.34      0.37     11004\n",
      "         car       0.39      0.24      0.29      1932\n",
      "     bicycle       0.24      0.10      0.14       316\n",
      "  motorcycle       0.29      0.13      0.18       371\n",
      "         bus       0.33      0.31      0.32       285\n",
      "       truck       0.29      0.04      0.07       415\n",
      "\n",
      "   micro avg       0.40      0.30      0.34     14323\n",
      "   macro avg       0.32      0.19      0.23     14323\n",
      "weighted avg       0.39      0.30      0.34     14323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "if len(label2idx) > 10:\n",
    "    counts = dataset.count_values(\"ground_truth.detections.label\")\n",
    "    classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "else:\n",
    "    classes_top10 = list(label2idx.keys())\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objrecognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
