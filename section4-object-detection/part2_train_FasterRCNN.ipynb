{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pyml/anaconda3/envs/objrecognition/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision  \n",
    "from torchvision.io import read_image\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from loguru import logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fasterrcnn_model(num_classes):\n",
    "    # load a model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "        weights=\"DEFAULT\"\n",
    "    )\n",
    "\n",
    "    # replace the classifier with a new one, that has\n",
    "    # num_classes which is user-defined\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "        in_features, num_classes\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label mapping\n",
    "label_mapping = {\n",
    "    \"person\": 1,\n",
    "    \"car\": 2,\n",
    "    \"bicycle\": 3,\n",
    "    \"motorcycle\": 4,\n",
    "    \"bus\": 5,\n",
    "    \"truck\": 6\n",
    "}\n",
    "\n",
    "# Function to convert string labels to numerical labels\n",
    "def convert_labels_to_numbers(labels):\n",
    "    return [label_mapping[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class MyDetectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, transforms=None, tag=\"train\"):\n",
    "        self.transforms = transforms\n",
    "        self.tag = tag\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df_selected = df[df[\"tag\"] == tag]\n",
    "        self.img_files = df_selected[\"imagepath\"].values\n",
    "        self.annot_files = df_selected[\"labelpath\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_files[idx]\n",
    "        mask_path = self.annot_files[idx]\n",
    "        img = read_image(img_path)\n",
    "        with open(mask_path, \"rt\") as f:\n",
    "            d_json = json.load(f)\n",
    "        # example:\n",
    "        # [{\"label\": \"person\", \"x\": 167, \"y\": 162, \"width\": 310, \"height\": 465}]\n",
    "        num_objs = len(d_json)\n",
    "\n",
    "        labels = convert_labels_to_numbers(\n",
    "            [obj[\"label\"] for obj in d_json]\n",
    "        )\n",
    "        boxes_xywh = [\n",
    "            (obj[\"x\"], obj[\"y\"], obj[\"width\"], obj[\"height\"])\n",
    "            for obj in d_json\n",
    "            if (obj[\"width\"] > 0) and (obj[\"height\"] > 0)\n",
    "        ]\n",
    "        boxes_xywh = torch.tensor(boxes_xywh, dtype=torch.float32)\n",
    "        boxes = torchvision.ops.box_convert(\n",
    "            boxes_xywh, in_fmt=\"xywh\", out_fmt=\"xyxy\"\n",
    "        )\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        image_id = idx\n",
    "\n",
    "        # Wrap sample and targets into torchvision tv_tensors:\n",
    "        img = tv_tensors.Image(img)\n",
    "        target = {\n",
    "            \"boxes\": tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img)),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.int64),\n",
    "            \"image_id\": image_id,\n",
    "            \"area\": area,\n",
    "            \"iscrowd\": iscrowd\n",
    "        }\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        if self.tag == \"test\":\n",
    "            return img_path, img, target\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-10-01 22:01:14--  https://raw.githubusercontent.com/pytorch/vision/master/references/detection/engine.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8000::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4063 (4.0K) [text/plain]\n",
      "Saving to: ‘code/engine.py.4’\n",
      "\n",
      "     0K ...                                                   100% 1017K=0.004s\n",
      "\n",
      "2024-10-01 22:01:14 (1017 KB/s) - ‘code/engine.py.4’ saved [4063/4063]\n",
      "\n",
      "--2024-10-01 22:01:14--  https://raw.githubusercontent.com/pytorch/vision/master/references/detection/utils.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8003::154, 2606:50c0:8000::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8388 (8.2K) [text/plain]\n",
      "Saving to: ‘code/utils.py.4’\n",
      "\n",
      "     0K ........                                              100% 58.6M=0s\n",
      "\n",
      "2024-10-01 22:01:14 (58.6 MB/s) - ‘code/utils.py.4’ saved [8388/8388]\n",
      "\n",
      "--2024-10-01 22:01:14--  https://raw.githubusercontent.com/pytorch/vision/master/references/detection/transforms.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8003::154, 2606:50c0:8000::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23628 (23K) [text/plain]\n",
      "Saving to: ‘code/transforms.py.4’\n",
      "\n",
      "     0K .......... .......... ...                             100% 29.8M=0.001s\n",
      "\n",
      "2024-10-01 22:01:14 (29.8 MB/s) - ‘code/transforms.py.4’ saved [23628/23628]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "os_type = platform.system()\n",
    "\n",
    "os.makedirs(\"code/\", exist_ok=True)\n",
    "\n",
    "if os_type == \"Linux\":\n",
    "    os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/master/references/detection/engine.py -P code/\")\n",
    "    os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/master/references/detection/utils.py -P code/\")\n",
    "    os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/master/references/detection/transforms.py -P code/\")\n",
    "elif os_type == \"Darwin\":\n",
    "    os.system(\"curl https://raw.githubusercontent.com/pytorch/vision/master/references/detection/engine.py -o code/engine.py\")\n",
    "    os.system(\"curl https://raw.githubusercontent.com/pytorch/vision/master/references/detection/utils.py -o code/utils.py\")\n",
    "    os.system(\"curl https://raw.githubusercontent.com/pytorch/vision/master/references/detection/transforms.py -o code/transforms.py\")\n",
    "else:\n",
    "    logger.error(\"OS not supported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_box_reg': tensor(0.5500, grad_fn=<DivBackward0>),\n",
      " 'loss_classifier': tensor(2.1534, grad_fn=<NllLossBackward0>),\n",
      " 'loss_objectness': tensor(0.0490, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
      " 'loss_rpn_box_reg': tensor(0.0141, grad_fn=<DivBackward0>)}\n",
      "{'boxes': tensor([[  0.0000,  41.0168, 303.5200, 279.0636],\n",
      "        [195.5486,  17.0852, 392.7163,  80.6631],\n",
      "        [105.8574,   0.0000, 324.4152, 237.7843],\n",
      "        [ 12.5271,   0.0000, 228.5193, 228.2327],\n",
      "        [ 70.7924,  71.8132,  74.6952,  75.8360],\n",
      "        [101.4217,  15.9934, 383.3571, 151.5665],\n",
      "        [193.9711,  36.6921, 393.4330, 118.6016],\n",
      "        [136.2682,  71.7459, 342.9651, 212.3316],\n",
      "        [ 62.2193,  33.5139, 283.3537, 171.8978],\n",
      "        [ 40.3806,  90.6082, 266.2570, 233.5205],\n",
      "        [163.4564,  89.9357, 168.0202,  93.0731],\n",
      "        [ 13.0182,   0.0000, 383.7056,  99.9642],\n",
      "        [161.4269,  90.5458, 166.7726,  93.7259],\n",
      "        [229.1256, 183.8250, 232.5662, 188.5283],\n",
      "        [177.2903,  46.9330, 380.5668, 193.7344],\n",
      "        [  0.0000, 138.6249, 400.0000, 283.7343],\n",
      "        [160.3183,  89.8445, 164.9412,  92.8269],\n",
      "        [161.1495,  88.9156, 165.9703,  91.8356],\n",
      "        [  0.0000,  13.4771, 252.1863, 158.5020],\n",
      "        [270.5048,  73.5078, 274.0025,  77.1613],\n",
      "        [  0.0000, 113.5806, 183.9227, 283.7631],\n",
      "        [268.6774,  72.7807, 272.9576,  76.2390],\n",
      "        [298.3852,  20.0821, 379.1415, 172.6144],\n",
      "        [  0.0000,  42.9227, 357.3202, 202.9648],\n",
      "        [192.9270, 190.6142, 196.8474, 193.7296],\n",
      "        [193.0651, 191.8419, 196.9003, 194.9605],\n",
      "        [ 29.8889,  35.3727, 250.2492, 116.8168],\n",
      "        [243.2882,  96.7239, 246.7517, 100.6353],\n",
      "        [108.3690, 257.1982, 345.0858, 293.0498],\n",
      "        [280.4722,  14.2743, 393.4674, 258.7089],\n",
      "        [269.3696,  73.8648, 272.8931,  77.2432],\n",
      "        [ 13.3994,  52.7378, 207.1919, 186.6994],\n",
      "        [  0.0000,  35.5086, 110.4499, 277.8606],\n",
      "        [  3.2448,   7.0621, 400.0000, 156.0477],\n",
      "        [ 71.9167,  70.6257,  75.4947,  74.9482],\n",
      "        [291.5989, 208.8924, 296.8658, 215.0642],\n",
      "        [ 67.1602,  24.4114, 387.6085, 292.6563],\n",
      "        [254.3592, 230.8871, 259.4940, 234.9864],\n",
      "        [191.9168, 191.9333, 195.4575, 194.9218],\n",
      "        [227.2102, 184.0661, 230.6684, 189.2930],\n",
      "        [162.7462,  88.3043, 166.6588,  91.0695],\n",
      "        [ 70.8208,  69.4722,  74.6565,  73.8882],\n",
      "        [316.0648,  84.0594, 388.1965, 262.8013],\n",
      "        [340.3910, 116.0144, 344.2952, 119.7483],\n",
      "        [232.5277, 154.2708, 235.9317, 158.3644],\n",
      "        [132.0693,  84.0357, 135.7071,  88.8238],\n",
      "        [212.9626, 143.4951, 217.8069, 147.5954],\n",
      "        [153.3806,  95.7485, 355.3317, 236.9557],\n",
      "        [ 42.4341,   1.2346, 218.9715, 288.1837],\n",
      "        [268.7313,  72.8448, 273.3456,  76.7878],\n",
      "        [ 77.8742, 131.4371, 296.5958, 267.1814],\n",
      "        [138.1792, 172.1852, 398.8660, 295.0628],\n",
      "        [338.9813, 116.7716, 343.3074, 120.1648],\n",
      "        [263.4489, 182.9519, 267.9678, 188.1378],\n",
      "        [336.1683, 108.8865, 340.8069, 111.9205],\n",
      "        [230.0760, 184.2908, 234.2008, 188.5855],\n",
      "        [335.9918, 109.3217, 339.6877, 113.0056],\n",
      "        [  0.0000, 219.6260, 393.5009, 296.2741],\n",
      "        [243.1748, 147.5107, 246.3993, 150.7753],\n",
      "        [  0.0000,  18.4461, 396.5712, 165.1337],\n",
      "        [214.2258, 143.0080, 218.9605, 147.3806],\n",
      "        [338.0724,  12.3195, 393.3935, 188.9191],\n",
      "        [320.0612, 209.0025, 324.0045, 212.8395],\n",
      "        [231.4823, 153.9623, 234.7046, 158.0604],\n",
      "        [307.4196, 209.0257, 311.3908, 213.3277],\n",
      "        [253.3072, 229.7235, 257.0788, 234.3291],\n",
      "        [178.3388, 237.2162, 400.0000, 285.6213],\n",
      "        [218.3992, 144.8763, 222.8058, 149.5336],\n",
      "        [341.7774, 113.0602, 344.9388, 116.4300],\n",
      "        [318.9390, 209.7018, 323.1761, 213.5411],\n",
      "        [192.4499, 192.9868, 196.1159, 195.8706],\n",
      "        [212.8377,  59.2614, 382.1230, 293.6377],\n",
      "        [244.5224, 147.4012, 247.7798, 150.5913],\n",
      "        [243.1831, 146.4467, 246.5775, 149.5456],\n",
      "        [  0.0000, 143.4331, 245.3018, 274.1469],\n",
      "        [188.9674,  84.1999, 193.3005,  88.4440],\n",
      "        [ 62.6250, 135.9508, 313.4282, 298.8162],\n",
      "        [223.6464, 185.0652, 227.5203, 189.7852],\n",
      "        [270.2316,  75.7381, 273.8252,  78.8452],\n",
      "        [155.2976,  21.3534, 372.3164, 166.8291],\n",
      "        [340.1824, 112.5764, 343.3172, 116.0786],\n",
      "        [179.5585, 186.0555, 183.5625, 189.2305],\n",
      "        [ 92.0932, 222.4064,  95.8932, 227.7273],\n",
      "        [247.0740,  97.3885, 250.8026, 101.2569],\n",
      "        [ 29.8237,  96.7186, 378.3584, 264.7756],\n",
      "        [214.5716,  64.1772, 389.5860, 297.0479],\n",
      "        [309.2592, 208.6275, 313.0888, 213.0101],\n",
      "        [ 73.5894,  71.5523,  76.6420,  75.7566],\n",
      "        [227.2557,  95.5363, 231.2698,  99.5053],\n",
      "        [230.6235, 182.9413, 234.1684, 187.1794],\n",
      "        [346.1069,  55.8268, 399.8479, 295.1672],\n",
      "        [227.7630, 151.9118, 231.5060, 155.9262],\n",
      "        [244.3872,  96.8503, 247.8293, 100.5316],\n",
      "        [253.6131, 232.3356, 259.0284, 236.4031],\n",
      "        [190.6422,  86.7406, 194.7200,  91.0328],\n",
      "        [192.7704, 193.4645, 197.0359, 196.7611],\n",
      "        [268.9557,  77.2507, 272.2360,  82.0467],\n",
      "        [ 90.0611,  72.5562, 293.5743, 213.0439],\n",
      "        [241.5274, 146.5426, 244.7721, 149.7470],\n",
      "        [248.6621, 180.2756, 252.7939, 184.7136]], grad_fn=<StackBackward0>),\n",
      " 'labels': tensor([5, 6, 5, 5, 3, 6, 6, 5, 5, 5, 6, 6, 6, 4, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6,\n",
      "        6, 6, 6, 3, 2, 6, 6, 6, 5, 5, 3, 6, 6, 4, 6, 4, 6, 3, 6, 4, 3, 3, 6, 6,\n",
      "        6, 4, 5, 6, 4, 6, 4, 4, 4, 5, 6, 3, 4, 6, 6, 3, 5, 4, 6, 5, 4, 6, 6, 6,\n",
      "        6, 6, 6, 4, 6, 4, 6, 5, 4, 5, 3, 4, 3, 5, 5, 3, 6, 4, 3, 5, 3, 4, 4, 6,\n",
      "        3, 6, 6, 6]),\n",
      " 'scores': tensor([0.2328, 0.2179, 0.2148, 0.2135, 0.2095, 0.2076, 0.2052, 0.2029, 0.2029,\n",
      "        0.2024, 0.2016, 0.1960, 0.1955, 0.1954, 0.1952, 0.1951, 0.1951, 0.1949,\n",
      "        0.1947, 0.1946, 0.1943, 0.1920, 0.1918, 0.1912, 0.1911, 0.1894, 0.1889,\n",
      "        0.1880, 0.1877, 0.1870, 0.1864, 0.1859, 0.1856, 0.1853, 0.1845, 0.1844,\n",
      "        0.1839, 0.1837, 0.1836, 0.1824, 0.1820, 0.1817, 0.1808, 0.1806, 0.1805,\n",
      "        0.1804, 0.1803, 0.1800, 0.1799, 0.1798, 0.1796, 0.1796, 0.1793, 0.1793,\n",
      "        0.1790, 0.1788, 0.1786, 0.1785, 0.1780, 0.1779, 0.1778, 0.1776, 0.1773,\n",
      "        0.1772, 0.1772, 0.1766, 0.1764, 0.1764, 0.1762, 0.1761, 0.1760, 0.1754,\n",
      "        0.1751, 0.1751, 0.1750, 0.1749, 0.1748, 0.1746, 0.1743, 0.1743, 0.1742,\n",
      "        0.1739, 0.1737, 0.1734, 0.1734, 0.1733, 0.1732, 0.1732, 0.1732, 0.1731,\n",
      "        0.1730, 0.1730, 0.1728, 0.1728, 0.1728, 0.1728, 0.1727, 0.1726, 0.1723,\n",
      "        0.1723], grad_fn=<IndexBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pprint\n",
    "sys.path.append(\"code/\")\n",
    "import utils\n",
    "\n",
    "\n",
    "dataset = MyDetectionDataset(\n",
    "    \"data/data.csv\",\n",
    "    transforms=get_transform(train=True),\n",
    "    tag=\"train\"\n",
    ")\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "num_classes = len(label_mapping) + 1  # 0: background, 1...N: classes\n",
    "model = get_fasterrcnn_model(num_classes=num_classes)\n",
    "\n",
    "\n",
    "# For Training\n",
    "images, targets = next(iter(data_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "output = model(images, targets)  # Returns losses and detections\n",
    "print(pprint.pformat(output))\n",
    "\n",
    "\n",
    "# For inference\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)  # Returns predictions\n",
    "\n",
    "print(pprint.pformat(predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/4000]  eta: 1:18:21  lr: 0.000010  loss: 2.6749 (2.6749)  loss_classifier: 1.9354 (1.9354)  loss_box_reg: 0.6395 (0.6395)  loss_objectness: 0.0761 (0.0761)  loss_rpn_box_reg: 0.0239 (0.0239)  time: 1.1754  data: 0.2604  max mem: 2352\n",
      "Epoch: [0]  [ 100/4000]  eta: 0:09:25  lr: 0.000509  loss: 0.8437 (1.2017)  loss_classifier: 0.2518 (0.6709)  loss_box_reg: 0.4521 (0.4715)  loss_objectness: 0.0164 (0.0285)  loss_rpn_box_reg: 0.0236 (0.0307)  time: 0.1388  data: 0.0024  max mem: 3931\n",
      "Epoch: [0]  [ 200/4000]  eta: 0:08:48  lr: 0.001009  loss: 0.4420 (0.8670)  loss_classifier: 0.1530 (0.4214)  loss_box_reg: 0.2583 (0.3863)  loss_objectness: 0.0106 (0.0262)  loss_rpn_box_reg: 0.0104 (0.0331)  time: 0.1301  data: 0.0023  max mem: 3931\n",
      "Epoch: [0]  [ 300/4000]  eta: 0:08:24  lr: 0.001508  loss: 0.5643 (0.7414)  loss_classifier: 0.1546 (0.3332)  loss_box_reg: 0.3036 (0.3455)  loss_objectness: 0.0133 (0.0270)  loss_rpn_box_reg: 0.0178 (0.0357)  time: 0.1357  data: 0.0023  max mem: 3931\n",
      "Epoch: [0]  [ 400/4000]  eta: 0:08:09  lr: 0.002008  loss: 0.3731 (0.6765)  loss_classifier: 0.1118 (0.2888)  loss_box_reg: 0.2110 (0.3228)  loss_objectness: 0.0105 (0.0266)  loss_rpn_box_reg: 0.0144 (0.0383)  time: 0.1358  data: 0.0023  max mem: 3931\n",
      "Epoch: [0]  [ 500/4000]  eta: 0:07:53  lr: 0.002507  loss: 0.3655 (0.6318)  loss_classifier: 0.1191 (0.2589)  loss_box_reg: 0.2326 (0.3076)  loss_objectness: 0.0114 (0.0261)  loss_rpn_box_reg: 0.0163 (0.0392)  time: 0.1305  data: 0.0022  max mem: 3931\n",
      "Epoch: [0]  [ 600/4000]  eta: 0:07:38  lr: 0.003007  loss: 0.3866 (0.6038)  loss_classifier: 0.1550 (0.2423)  loss_box_reg: 0.1860 (0.2959)  loss_objectness: 0.0132 (0.0264)  loss_rpn_box_reg: 0.0133 (0.0392)  time: 0.1379  data: 0.0023  max mem: 3931\n",
      "Epoch: [0]  [ 700/4000]  eta: 0:07:24  lr: 0.003506  loss: 0.2818 (0.5837)  loss_classifier: 0.1009 (0.2299)  loss_box_reg: 0.1416 (0.2868)  loss_objectness: 0.0135 (0.0271)  loss_rpn_box_reg: 0.0178 (0.0399)  time: 0.1308  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [ 800/4000]  eta: 0:07:11  lr: 0.004006  loss: 0.3698 (0.5688)  loss_classifier: 0.1427 (0.2205)  loss_box_reg: 0.1742 (0.2799)  loss_objectness: 0.0207 (0.0276)  loss_rpn_box_reg: 0.0211 (0.0409)  time: 0.1314  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [ 900/4000]  eta: 0:06:56  lr: 0.004505  loss: 0.3699 (0.5539)  loss_classifier: 0.1246 (0.2119)  loss_box_reg: 0.1814 (0.2714)  loss_objectness: 0.0422 (0.0291)  loss_rpn_box_reg: 0.0239 (0.0415)  time: 0.1294  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [1000/4000]  eta: 0:06:43  lr: 0.005000  loss: 0.5115 (0.5439)  loss_classifier: 0.1633 (0.2059)  loss_box_reg: 0.2424 (0.2657)  loss_objectness: 0.0396 (0.0306)  loss_rpn_box_reg: 0.0364 (0.0416)  time: 0.1392  data: 0.0024  max mem: 4213\n",
      "Epoch: [0]  [1100/4000]  eta: 0:06:30  lr: 0.005000  loss: 0.2477 (0.5412)  loss_classifier: 0.1112 (0.2032)  loss_box_reg: 0.1354 (0.2620)  loss_objectness: 0.0150 (0.0328)  loss_rpn_box_reg: 0.0139 (0.0432)  time: 0.1300  data: 0.0025  max mem: 4213\n",
      "Epoch: [0]  [1200/4000]  eta: 0:06:16  lr: 0.005000  loss: 0.3760 (0.5332)  loss_classifier: 0.1072 (0.1990)  loss_box_reg: 0.1544 (0.2583)  loss_objectness: 0.0191 (0.0325)  loss_rpn_box_reg: 0.0238 (0.0434)  time: 0.1305  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [1300/4000]  eta: 0:06:03  lr: 0.005000  loss: 0.4239 (0.5305)  loss_classifier: 0.1454 (0.1962)  loss_box_reg: 0.2521 (0.2553)  loss_objectness: 0.0259 (0.0347)  loss_rpn_box_reg: 0.0229 (0.0443)  time: 0.1348  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [1400/4000]  eta: 0:05:49  lr: 0.005000  loss: 0.4051 (0.5249)  loss_classifier: 0.1407 (0.1929)  loss_box_reg: 0.2152 (0.2527)  loss_objectness: 0.0318 (0.0353)  loss_rpn_box_reg: 0.0226 (0.0440)  time: 0.1341  data: 0.0025  max mem: 4213\n",
      "Epoch: [0]  [1500/4000]  eta: 0:05:36  lr: 0.005000  loss: 0.3047 (0.5161)  loss_classifier: 0.1170 (0.1892)  loss_box_reg: 0.1459 (0.2484)  loss_objectness: 0.0166 (0.0351)  loss_rpn_box_reg: 0.0183 (0.0434)  time: 0.1305  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [1600/4000]  eta: 0:05:22  lr: 0.005000  loss: 0.3087 (0.5126)  loss_classifier: 0.1325 (0.1869)  loss_box_reg: 0.1640 (0.2460)  loss_objectness: 0.0481 (0.0358)  loss_rpn_box_reg: 0.0145 (0.0439)  time: 0.1380  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [1700/4000]  eta: 0:05:09  lr: 0.005000  loss: 0.3521 (0.5078)  loss_classifier: 0.1089 (0.1842)  loss_box_reg: 0.1751 (0.2431)  loss_objectness: 0.0360 (0.0358)  loss_rpn_box_reg: 0.0170 (0.0446)  time: 0.1294  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [1800/4000]  eta: 0:04:56  lr: 0.005000  loss: 0.4424 (0.5052)  loss_classifier: 0.1501 (0.1828)  loss_box_reg: 0.2462 (0.2418)  loss_objectness: 0.0268 (0.0359)  loss_rpn_box_reg: 0.0316 (0.0446)  time: 0.1372  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [1900/4000]  eta: 0:04:43  lr: 0.005000  loss: 0.4415 (0.5011)  loss_classifier: 0.1780 (0.1811)  loss_box_reg: 0.1849 (0.2396)  loss_objectness: 0.0349 (0.0360)  loss_rpn_box_reg: 0.0335 (0.0444)  time: 0.1450  data: 0.0024  max mem: 4213\n",
      "Epoch: [0]  [2000/4000]  eta: 0:04:30  lr: 0.005000  loss: 0.2589 (0.4998)  loss_classifier: 0.0810 (0.1795)  loss_box_reg: 0.1493 (0.2389)  loss_objectness: 0.0155 (0.0362)  loss_rpn_box_reg: 0.0110 (0.0452)  time: 0.1349  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [2100/4000]  eta: 0:04:16  lr: 0.005000  loss: 0.4380 (0.4993)  loss_classifier: 0.1158 (0.1785)  loss_box_reg: 0.2013 (0.2388)  loss_objectness: 0.0378 (0.0364)  loss_rpn_box_reg: 0.0192 (0.0456)  time: 0.1269  data: 0.0026  max mem: 4213\n",
      "Epoch: [0]  [2200/4000]  eta: 0:04:03  lr: 0.005000  loss: 0.5017 (0.4967)  loss_classifier: 0.1629 (0.1769)  loss_box_reg: 0.2542 (0.2374)  loss_objectness: 0.0226 (0.0366)  loss_rpn_box_reg: 0.0243 (0.0457)  time: 0.1326  data: 0.0025  max mem: 4213\n",
      "Epoch: [0]  [2300/4000]  eta: 0:03:50  lr: 0.005000  loss: 0.3766 (0.4936)  loss_classifier: 0.1243 (0.1754)  loss_box_reg: 0.1884 (0.2357)  loss_objectness: 0.0267 (0.0368)  loss_rpn_box_reg: 0.0147 (0.0457)  time: 0.1376  data: 0.0025  max mem: 4213\n",
      "Epoch: [0]  [2400/4000]  eta: 0:03:37  lr: 0.005000  loss: 0.4630 (0.4926)  loss_classifier: 0.1624 (0.1745)  loss_box_reg: 0.2214 (0.2353)  loss_objectness: 0.0216 (0.0370)  loss_rpn_box_reg: 0.0270 (0.0459)  time: 0.1387  data: 0.0028  max mem: 4213\n",
      "Epoch: [0]  [2500/4000]  eta: 0:03:23  lr: 0.005000  loss: 0.2587 (0.4885)  loss_classifier: 0.0924 (0.1724)  loss_box_reg: 0.1167 (0.2327)  loss_objectness: 0.0256 (0.0374)  loss_rpn_box_reg: 0.0176 (0.0459)  time: 0.1343  data: 0.0026  max mem: 4213\n",
      "Epoch: [0]  [2600/4000]  eta: 0:03:10  lr: 0.005000  loss: 0.4014 (0.4884)  loss_classifier: 0.1330 (0.1719)  loss_box_reg: 0.1997 (0.2327)  loss_objectness: 0.0198 (0.0375)  loss_rpn_box_reg: 0.0256 (0.0463)  time: 0.1359  data: 0.0028  max mem: 4213\n",
      "Epoch: [0]  [2700/4000]  eta: 0:02:56  lr: 0.005000  loss: 0.4883 (0.4870)  loss_classifier: 0.1425 (0.1711)  loss_box_reg: 0.2521 (0.2323)  loss_objectness: 0.0271 (0.0372)  loss_rpn_box_reg: 0.0198 (0.0463)  time: 0.1382  data: 0.0026  max mem: 4213\n",
      "Epoch: [0]  [2800/4000]  eta: 0:02:43  lr: 0.005000  loss: 0.2219 (0.4830)  loss_classifier: 0.0801 (0.1698)  loss_box_reg: 0.1229 (0.2304)  loss_objectness: 0.0137 (0.0368)  loss_rpn_box_reg: 0.0123 (0.0460)  time: 0.1302  data: 0.0027  max mem: 4213\n",
      "Epoch: [0]  [2900/4000]  eta: 0:02:29  lr: 0.005000  loss: 0.3647 (0.4811)  loss_classifier: 0.1311 (0.1690)  loss_box_reg: 0.1845 (0.2296)  loss_objectness: 0.0241 (0.0364)  loss_rpn_box_reg: 0.0197 (0.0460)  time: 0.1410  data: 0.0024  max mem: 4213\n",
      "Epoch: [0]  [3000/4000]  eta: 0:02:16  lr: 0.005000  loss: 0.2992 (0.4789)  loss_classifier: 0.0941 (0.1681)  loss_box_reg: 0.1625 (0.2288)  loss_objectness: 0.0172 (0.0363)  loss_rpn_box_reg: 0.0112 (0.0457)  time: 0.1453  data: 0.0024  max mem: 4213\n",
      "Epoch: [0]  [3100/4000]  eta: 0:02:02  lr: 0.005000  loss: 0.3919 (0.4781)  loss_classifier: 0.1238 (0.1675)  loss_box_reg: 0.1868 (0.2282)  loss_objectness: 0.0153 (0.0366)  loss_rpn_box_reg: 0.0279 (0.0459)  time: 0.1439  data: 0.0025  max mem: 4213\n",
      "Epoch: [0]  [3200/4000]  eta: 0:01:49  lr: 0.005000  loss: 0.3860 (0.4767)  loss_classifier: 0.1348 (0.1667)  loss_box_reg: 0.2184 (0.2275)  loss_objectness: 0.0231 (0.0364)  loss_rpn_box_reg: 0.0171 (0.0461)  time: 0.1381  data: 0.0027  max mem: 4213\n",
      "Epoch: [0]  [3300/4000]  eta: 0:01:35  lr: 0.005000  loss: 0.3103 (0.4743)  loss_classifier: 0.1175 (0.1658)  loss_box_reg: 0.1312 (0.2264)  loss_objectness: 0.0109 (0.0361)  loss_rpn_box_reg: 0.0234 (0.0460)  time: 0.1393  data: 0.0026  max mem: 4213\n",
      "Epoch: [0]  [3400/4000]  eta: 0:01:21  lr: 0.005000  loss: 0.3297 (0.4729)  loss_classifier: 0.1098 (0.1651)  loss_box_reg: 0.1946 (0.2261)  loss_objectness: 0.0109 (0.0357)  loss_rpn_box_reg: 0.0132 (0.0459)  time: 0.1347  data: 0.0028  max mem: 4213\n",
      "Epoch: [0]  [3500/4000]  eta: 0:01:08  lr: 0.005000  loss: 0.4516 (0.4709)  loss_classifier: 0.1347 (0.1642)  loss_box_reg: 0.2230 (0.2251)  loss_objectness: 0.0542 (0.0360)  loss_rpn_box_reg: 0.0221 (0.0457)  time: 0.1421  data: 0.0026  max mem: 4213\n",
      "Epoch: [0]  [3600/4000]  eta: 0:00:54  lr: 0.005000  loss: 0.4591 (0.4704)  loss_classifier: 0.1338 (0.1637)  loss_box_reg: 0.2283 (0.2243)  loss_objectness: 0.0434 (0.0366)  loss_rpn_box_reg: 0.0282 (0.0458)  time: 0.1398  data: 0.0029  max mem: 4213\n",
      "Epoch: [0]  [3700/4000]  eta: 0:00:40  lr: 0.005000  loss: 0.5673 (0.4704)  loss_classifier: 0.2024 (0.1638)  loss_box_reg: 0.2651 (0.2243)  loss_objectness: 0.0265 (0.0367)  loss_rpn_box_reg: 0.0315 (0.0456)  time: 0.1401  data: 0.0023  max mem: 4213\n",
      "Epoch: [0]  [3800/4000]  eta: 0:00:27  lr: 0.005000  loss: 0.4752 (0.4705)  loss_classifier: 0.1597 (0.1640)  loss_box_reg: 0.2318 (0.2242)  loss_objectness: 0.0367 (0.0367)  loss_rpn_box_reg: 0.0228 (0.0457)  time: 0.1439  data: 0.0028  max mem: 4213\n",
      "Epoch: [0]  [3900/4000]  eta: 0:00:13  lr: 0.005000  loss: 0.3042 (0.4688)  loss_classifier: 0.1031 (0.1632)  loss_box_reg: 0.1567 (0.2232)  loss_objectness: 0.0114 (0.0366)  loss_rpn_box_reg: 0.0141 (0.0459)  time: 0.1448  data: 0.0029  max mem: 4213\n",
      "Epoch: [0]  [3999/4000]  eta: 0:00:00  lr: 0.005000  loss: 0.3107 (0.4677)  loss_classifier: 0.0960 (0.1627)  loss_box_reg: 0.1800 (0.2227)  loss_objectness: 0.0223 (0.0366)  loss_rpn_box_reg: 0.0135 (0.0456)  time: 0.1373  data: 0.0032  max mem: 4213\n",
      "Epoch: [0] Total time: 0:09:07 (0.1368 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [   0/2000]  eta: 0:09:03  model_time: 0.0891 (0.0891)  evaluator_time: 0.0018 (0.0018)  time: 0.2719  data: 0.1800  max mem: 4213\n",
      "Test:  [ 100/2000]  eta: 0:01:19  model_time: 0.0290 (0.0367)  evaluator_time: 0.0007 (0.0016)  time: 0.0320  data: 0.0013  max mem: 4213\n",
      "Test:  [ 200/2000]  eta: 0:01:09  model_time: 0.0300 (0.0345)  evaluator_time: 0.0007 (0.0016)  time: 0.0330  data: 0.0012  max mem: 4213\n",
      "Test:  [ 300/2000]  eta: 0:01:03  model_time: 0.0306 (0.0334)  evaluator_time: 0.0008 (0.0016)  time: 0.0337  data: 0.0012  max mem: 4213\n",
      "Test:  [ 400/2000]  eta: 0:00:59  model_time: 0.0315 (0.0332)  evaluator_time: 0.0009 (0.0016)  time: 0.0348  data: 0.0012  max mem: 4213\n",
      "Test:  [ 500/2000]  eta: 0:00:55  model_time: 0.0310 (0.0330)  evaluator_time: 0.0010 (0.0016)  time: 0.0352  data: 0.0013  max mem: 4213\n",
      "Test:  [ 600/2000]  eta: 0:00:50  model_time: 0.0311 (0.0328)  evaluator_time: 0.0006 (0.0016)  time: 0.0358  data: 0.0012  max mem: 4213\n",
      "Test:  [ 700/2000]  eta: 0:00:46  model_time: 0.0310 (0.0326)  evaluator_time: 0.0008 (0.0016)  time: 0.0346  data: 0.0013  max mem: 4213\n",
      "Test:  [ 800/2000]  eta: 0:00:43  model_time: 0.0324 (0.0325)  evaluator_time: 0.0007 (0.0016)  time: 0.0371  data: 0.0013  max mem: 4213\n",
      "Test:  [ 900/2000]  eta: 0:00:39  model_time: 0.0322 (0.0324)  evaluator_time: 0.0008 (0.0016)  time: 0.0352  data: 0.0013  max mem: 4213\n",
      "Test:  [1000/2000]  eta: 0:00:35  model_time: 0.0332 (0.0325)  evaluator_time: 0.0006 (0.0016)  time: 0.0356  data: 0.0012  max mem: 4213\n",
      "Test:  [1100/2000]  eta: 0:00:32  model_time: 0.0329 (0.0325)  evaluator_time: 0.0008 (0.0017)  time: 0.0420  data: 0.0013  max mem: 4213\n",
      "Test:  [1200/2000]  eta: 0:00:28  model_time: 0.0331 (0.0326)  evaluator_time: 0.0007 (0.0017)  time: 0.0364  data: 0.0013  max mem: 4213\n",
      "Test:  [1300/2000]  eta: 0:00:25  model_time: 0.0331 (0.0326)  evaluator_time: 0.0008 (0.0017)  time: 0.0359  data: 0.0013  max mem: 4213\n",
      "Test:  [1400/2000]  eta: 0:00:21  model_time: 0.0329 (0.0327)  evaluator_time: 0.0007 (0.0017)  time: 0.0355  data: 0.0013  max mem: 4213\n",
      "Test:  [1500/2000]  eta: 0:00:18  model_time: 0.0333 (0.0327)  evaluator_time: 0.0006 (0.0016)  time: 0.0358  data: 0.0013  max mem: 4213\n",
      "Test:  [1600/2000]  eta: 0:00:14  model_time: 0.0336 (0.0328)  evaluator_time: 0.0008 (0.0016)  time: 0.0384  data: 0.0013  max mem: 4213\n",
      "Test:  [1700/2000]  eta: 0:00:10  model_time: 0.0339 (0.0328)  evaluator_time: 0.0007 (0.0016)  time: 0.0366  data: 0.0013  max mem: 4213\n",
      "Test:  [1800/2000]  eta: 0:00:07  model_time: 0.0335 (0.0329)  evaluator_time: 0.0011 (0.0017)  time: 0.0378  data: 0.0013  max mem: 4213\n",
      "Test:  [1900/2000]  eta: 0:00:03  model_time: 0.0338 (0.0329)  evaluator_time: 0.0007 (0.0017)  time: 0.0372  data: 0.0013  max mem: 4213\n",
      "Test:  [1999/2000]  eta: 0:00:00  model_time: 0.0332 (0.0329)  evaluator_time: 0.0013 (0.0017)  time: 0.0372  data: 0.0013  max mem: 4213\n",
      "Test: Total time: 0:01:12 (0.0365 s / it)\n",
      "Averaged stats: model_time: 0.0332 (0.0329)  evaluator_time: 0.0013 (0.0017)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.494\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.410\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
      "Epoch: [1]  [   0/4000]  eta: 0:23:20  lr: 0.005000  loss: 0.6801 (0.6801)  loss_classifier: 0.2628 (0.2628)  loss_box_reg: 0.2853 (0.2853)  loss_objectness: 0.0758 (0.0758)  loss_rpn_box_reg: 0.0562 (0.0562)  time: 0.3502  data: 0.2154  max mem: 4213\n",
      "Epoch: [1]  [ 100/4000]  eta: 0:09:19  lr: 0.005000  loss: 0.4937 (0.4495)  loss_classifier: 0.1897 (0.1571)  loss_box_reg: 0.2634 (0.2197)  loss_objectness: 0.0178 (0.0289)  loss_rpn_box_reg: 0.0193 (0.0438)  time: 0.1447  data: 0.0027  max mem: 4213\n",
      "Epoch: [1]  [ 200/4000]  eta: 0:08:57  lr: 0.005000  loss: 0.4454 (0.4287)  loss_classifier: 0.1445 (0.1488)  loss_box_reg: 0.2404 (0.2086)  loss_objectness: 0.0192 (0.0290)  loss_rpn_box_reg: 0.0187 (0.0423)  time: 0.1366  data: 0.0031  max mem: 4213\n",
      "Epoch: [1]  [ 300/4000]  eta: 0:08:42  lr: 0.005000  loss: 0.3329 (0.4182)  loss_classifier: 0.1397 (0.1445)  loss_box_reg: 0.1345 (0.2044)  loss_objectness: 0.0193 (0.0281)  loss_rpn_box_reg: 0.0180 (0.0413)  time: 0.1388  data: 0.0028  max mem: 4213\n",
      "Epoch: [1]  [ 400/4000]  eta: 0:08:24  lr: 0.005000  loss: 0.4133 (0.4271)  loss_classifier: 0.1500 (0.1467)  loss_box_reg: 0.2112 (0.2081)  loss_objectness: 0.0260 (0.0302)  loss_rpn_box_reg: 0.0196 (0.0420)  time: 0.1390  data: 0.0032  max mem: 4213\n",
      "Epoch: [1]  [ 500/4000]  eta: 0:08:12  lr: 0.005000  loss: 0.3317 (0.4259)  loss_classifier: 0.1058 (0.1442)  loss_box_reg: 0.1747 (0.2090)  loss_objectness: 0.0153 (0.0301)  loss_rpn_box_reg: 0.0106 (0.0425)  time: 0.1400  data: 0.0030  max mem: 4213\n",
      "Epoch: [1]  [ 600/4000]  eta: 0:08:00  lr: 0.005000  loss: 0.5160 (0.4264)  loss_classifier: 0.1637 (0.1444)  loss_box_reg: 0.2085 (0.2091)  loss_objectness: 0.0274 (0.0298)  loss_rpn_box_reg: 0.0210 (0.0432)  time: 0.1450  data: 0.0032  max mem: 4213\n",
      "Epoch: [1]  [ 700/4000]  eta: 0:07:48  lr: 0.005000  loss: 0.2716 (0.4240)  loss_classifier: 0.1127 (0.1431)  loss_box_reg: 0.1261 (0.2071)  loss_objectness: 0.0373 (0.0299)  loss_rpn_box_reg: 0.0267 (0.0438)  time: 0.1473  data: 0.0029  max mem: 4213\n",
      "Epoch: [1]  [ 800/4000]  eta: 0:07:35  lr: 0.005000  loss: 0.3291 (0.4261)  loss_classifier: 0.1268 (0.1431)  loss_box_reg: 0.1574 (0.2066)  loss_objectness: 0.0227 (0.0305)  loss_rpn_box_reg: 0.0142 (0.0459)  time: 0.1463  data: 0.0031  max mem: 4213\n",
      "Epoch: [1]  [ 900/4000]  eta: 0:07:22  lr: 0.005000  loss: 0.3939 (0.4322)  loss_classifier: 0.1298 (0.1445)  loss_box_reg: 0.1891 (0.2085)  loss_objectness: 0.0186 (0.0314)  loss_rpn_box_reg: 0.0114 (0.0477)  time: 0.1414  data: 0.0033  max mem: 4213\n",
      "Epoch: [1]  [1000/4000]  eta: 0:07:08  lr: 0.005000  loss: 0.4723 (0.4293)  loss_classifier: 0.1516 (0.1442)  loss_box_reg: 0.2163 (0.2081)  loss_objectness: 0.0195 (0.0308)  loss_rpn_box_reg: 0.0280 (0.0462)  time: 0.1450  data: 0.0028  max mem: 4213\n",
      "Epoch: [1]  [1100/4000]  eta: 0:06:54  lr: 0.005000  loss: 0.2832 (0.4270)  loss_classifier: 0.0855 (0.1435)  loss_box_reg: 0.1764 (0.2068)  loss_objectness: 0.0141 (0.0306)  loss_rpn_box_reg: 0.0158 (0.0462)  time: 0.1442  data: 0.0030  max mem: 4213\n",
      "Epoch: [1]  [1200/4000]  eta: 0:06:41  lr: 0.005000  loss: 0.4235 (0.4272)  loss_classifier: 0.1548 (0.1434)  loss_box_reg: 0.2022 (0.2058)  loss_objectness: 0.0299 (0.0317)  loss_rpn_box_reg: 0.0213 (0.0463)  time: 0.1516  data: 0.0027  max mem: 4213\n",
      "Epoch: [1]  [1300/4000]  eta: 0:06:28  lr: 0.005000  loss: 0.2494 (0.4256)  loss_classifier: 0.0915 (0.1425)  loss_box_reg: 0.1265 (0.2059)  loss_objectness: 0.0147 (0.0313)  loss_rpn_box_reg: 0.0084 (0.0459)  time: 0.1518  data: 0.0028  max mem: 4213\n",
      "Epoch: [1]  [1400/4000]  eta: 0:06:15  lr: 0.005000  loss: 0.5116 (0.4277)  loss_classifier: 0.1827 (0.1436)  loss_box_reg: 0.2477 (0.2063)  loss_objectness: 0.0209 (0.0317)  loss_rpn_box_reg: 0.0339 (0.0461)  time: 0.1513  data: 0.0029  max mem: 4213\n",
      "Epoch: [1]  [1500/4000]  eta: 0:06:02  lr: 0.005000  loss: 0.4260 (0.4242)  loss_classifier: 0.1656 (0.1433)  loss_box_reg: 0.2055 (0.2047)  loss_objectness: 0.0114 (0.0313)  loss_rpn_box_reg: 0.0172 (0.0449)  time: 0.1613  data: 0.0028  max mem: 4213\n",
      "Epoch: [1]  [1600/4000]  eta: 0:05:48  lr: 0.005000  loss: 0.4259 (0.4238)  loss_classifier: 0.1411 (0.1434)  loss_box_reg: 0.2129 (0.2044)  loss_objectness: 0.0231 (0.0314)  loss_rpn_box_reg: 0.0227 (0.0446)  time: 0.1461  data: 0.0032  max mem: 4213\n",
      "Epoch: [1]  [1700/4000]  eta: 0:05:34  lr: 0.005000  loss: 0.2758 (0.4246)  loss_classifier: 0.1226 (0.1445)  loss_box_reg: 0.1170 (0.2045)  loss_objectness: 0.0193 (0.0316)  loss_rpn_box_reg: 0.0136 (0.0440)  time: 0.1532  data: 0.0030  max mem: 4213\n",
      "Epoch: [1]  [1800/4000]  eta: 0:05:20  lr: 0.005000  loss: 0.4346 (0.4251)  loss_classifier: 0.1369 (0.1445)  loss_box_reg: 0.2003 (0.2045)  loss_objectness: 0.0348 (0.0316)  loss_rpn_box_reg: 0.0204 (0.0445)  time: 0.1571  data: 0.0028  max mem: 4213\n",
      "Epoch: [1]  [1900/4000]  eta: 0:05:06  lr: 0.005000  loss: 0.3078 (0.4249)  loss_classifier: 0.1230 (0.1445)  loss_box_reg: 0.1685 (0.2049)  loss_objectness: 0.0154 (0.0314)  loss_rpn_box_reg: 0.0109 (0.0441)  time: 0.1496  data: 0.0030  max mem: 4213\n",
      "Epoch: [1]  [2000/4000]  eta: 0:04:52  lr: 0.005000  loss: 0.2798 (0.4239)  loss_classifier: 0.1154 (0.1441)  loss_box_reg: 0.1190 (0.2042)  loss_objectness: 0.0330 (0.0315)  loss_rpn_box_reg: 0.0123 (0.0440)  time: 0.1513  data: 0.0029  max mem: 4213\n",
      "Epoch: [1]  [2100/4000]  eta: 0:04:38  lr: 0.005000  loss: 0.4357 (0.4258)  loss_classifier: 0.1447 (0.1446)  loss_box_reg: 0.2624 (0.2054)  loss_objectness: 0.0352 (0.0319)  loss_rpn_box_reg: 0.0212 (0.0439)  time: 0.1532  data: 0.0031  max mem: 4213\n",
      "Epoch: [1]  [2200/4000]  eta: 0:04:24  lr: 0.005000  loss: 0.3370 (0.4259)  loss_classifier: 0.1032 (0.1443)  loss_box_reg: 0.1989 (0.2058)  loss_objectness: 0.0210 (0.0318)  loss_rpn_box_reg: 0.0162 (0.0439)  time: 0.1522  data: 0.0029  max mem: 4304\n",
      "Epoch: [1]  [2300/4000]  eta: 0:04:09  lr: 0.005000  loss: 0.3086 (0.4257)  loss_classifier: 0.1153 (0.1444)  loss_box_reg: 0.1129 (0.2055)  loss_objectness: 0.0256 (0.0319)  loss_rpn_box_reg: 0.0206 (0.0439)  time: 0.1464  data: 0.0030  max mem: 4304\n",
      "Epoch: [1]  [2400/4000]  eta: 0:03:55  lr: 0.005000  loss: 0.3298 (0.4261)  loss_classifier: 0.1272 (0.1445)  loss_box_reg: 0.1934 (0.2056)  loss_objectness: 0.0100 (0.0318)  loss_rpn_box_reg: 0.0219 (0.0441)  time: 0.1535  data: 0.0033  max mem: 4304\n",
      "Epoch: [1]  [2500/4000]  eta: 0:03:41  lr: 0.005000  loss: 0.4206 (0.4255)  loss_classifier: 0.1316 (0.1445)  loss_box_reg: 0.2159 (0.2054)  loss_objectness: 0.0333 (0.0319)  loss_rpn_box_reg: 0.0200 (0.0436)  time: 0.1552  data: 0.0031  max mem: 4304\n",
      "Epoch: [1]  [2600/4000]  eta: 0:03:26  lr: 0.005000  loss: 0.2996 (0.4268)  loss_classifier: 0.1164 (0.1448)  loss_box_reg: 0.1343 (0.2060)  loss_objectness: 0.0141 (0.0320)  loss_rpn_box_reg: 0.0266 (0.0440)  time: 0.1535  data: 0.0033  max mem: 4304\n",
      "Epoch: [1]  [2700/4000]  eta: 0:03:12  lr: 0.005000  loss: 0.2919 (0.4256)  loss_classifier: 0.1172 (0.1445)  loss_box_reg: 0.1239 (0.2055)  loss_objectness: 0.0179 (0.0318)  loss_rpn_box_reg: 0.0186 (0.0439)  time: 0.1519  data: 0.0031  max mem: 4304\n",
      "Epoch: [1]  [2800/4000]  eta: 0:02:57  lr: 0.005000  loss: 0.3296 (0.4262)  loss_classifier: 0.1196 (0.1447)  loss_box_reg: 0.1429 (0.2055)  loss_objectness: 0.0172 (0.0320)  loss_rpn_box_reg: 0.0277 (0.0439)  time: 0.1530  data: 0.0034  max mem: 4304\n",
      "Epoch: [1]  [2900/4000]  eta: 0:02:42  lr: 0.005000  loss: 0.3540 (0.4264)  loss_classifier: 0.0948 (0.1445)  loss_box_reg: 0.1722 (0.2054)  loss_objectness: 0.0303 (0.0321)  loss_rpn_box_reg: 0.0176 (0.0443)  time: 0.1528  data: 0.0031  max mem: 4304\n",
      "Epoch: [1]  [3000/4000]  eta: 0:02:28  lr: 0.005000  loss: 0.3177 (0.4250)  loss_classifier: 0.1383 (0.1442)  loss_box_reg: 0.1184 (0.2046)  loss_objectness: 0.0170 (0.0320)  loss_rpn_box_reg: 0.0137 (0.0443)  time: 0.1538  data: 0.0031  max mem: 4304\n",
      "Epoch: [1]  [3100/4000]  eta: 0:02:13  lr: 0.005000  loss: 0.4674 (0.4266)  loss_classifier: 0.1619 (0.1447)  loss_box_reg: 0.2105 (0.2054)  loss_objectness: 0.0260 (0.0320)  loss_rpn_box_reg: 0.0251 (0.0445)  time: 0.1550  data: 0.0033  max mem: 4304\n",
      "Epoch: [1]  [3200/4000]  eta: 0:01:58  lr: 0.005000  loss: 0.2794 (0.4252)  loss_classifier: 0.0913 (0.1441)  loss_box_reg: 0.1494 (0.2048)  loss_objectness: 0.0199 (0.0319)  loss_rpn_box_reg: 0.0184 (0.0443)  time: 0.1544  data: 0.0032  max mem: 4304\n",
      "Epoch: [1]  [3300/4000]  eta: 0:01:43  lr: 0.005000  loss: 0.5107 (0.4251)  loss_classifier: 0.1742 (0.1441)  loss_box_reg: 0.2302 (0.2048)  loss_objectness: 0.0432 (0.0319)  loss_rpn_box_reg: 0.0265 (0.0443)  time: 0.1518  data: 0.0025  max mem: 4304\n",
      "Epoch: [1]  [3400/4000]  eta: 0:01:29  lr: 0.005000  loss: 0.4463 (0.4251)  loss_classifier: 0.1352 (0.1442)  loss_box_reg: 0.2581 (0.2047)  loss_objectness: 0.0146 (0.0318)  loss_rpn_box_reg: 0.0195 (0.0443)  time: 0.1541  data: 0.0031  max mem: 4304\n",
      "Epoch: [1]  [3500/4000]  eta: 0:01:14  lr: 0.005000  loss: 0.2418 (0.4255)  loss_classifier: 0.1026 (0.1446)  loss_box_reg: 0.1088 (0.2049)  loss_objectness: 0.0145 (0.0317)  loss_rpn_box_reg: 0.0200 (0.0442)  time: 0.1547  data: 0.0032  max mem: 4304\n",
      "Epoch: [1]  [3600/4000]  eta: 0:00:59  lr: 0.005000  loss: 0.3224 (0.4250)  loss_classifier: 0.1105 (0.1446)  loss_box_reg: 0.1623 (0.2045)  loss_objectness: 0.0099 (0.0317)  loss_rpn_box_reg: 0.0225 (0.0443)  time: 0.1528  data: 0.0028  max mem: 4304\n",
      "Epoch: [1]  [3700/4000]  eta: 0:00:44  lr: 0.005000  loss: 0.3270 (0.4252)  loss_classifier: 0.1232 (0.1445)  loss_box_reg: 0.1637 (0.2047)  loss_objectness: 0.0169 (0.0316)  loss_rpn_box_reg: 0.0135 (0.0444)  time: 0.1489  data: 0.0031  max mem: 4304\n",
      "Epoch: [1]  [3800/4000]  eta: 0:00:29  lr: 0.005000  loss: 0.3046 (0.4252)  loss_classifier: 0.0977 (0.1444)  loss_box_reg: 0.1491 (0.2048)  loss_objectness: 0.0127 (0.0316)  loss_rpn_box_reg: 0.0097 (0.0444)  time: 0.1474  data: 0.0033  max mem: 4304\n",
      "Epoch: [1]  [3900/4000]  eta: 0:00:14  lr: 0.005000  loss: 0.2156 (0.4244)  loss_classifier: 0.0794 (0.1443)  loss_box_reg: 0.1432 (0.2045)  loss_objectness: 0.0184 (0.0315)  loss_rpn_box_reg: 0.0117 (0.0441)  time: 0.1516  data: 0.0029  max mem: 4304\n",
      "Epoch: [1]  [3999/4000]  eta: 0:00:00  lr: 0.005000  loss: 0.2918 (0.4256)  loss_classifier: 0.1216 (0.1447)  loss_box_reg: 0.1426 (0.2050)  loss_objectness: 0.0218 (0.0316)  loss_rpn_box_reg: 0.0153 (0.0443)  time: 0.1497  data: 0.0032  max mem: 4304\n",
      "Epoch: [1] Total time: 0:09:56 (0.1491 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [   0/2000]  eta: 0:08:56  model_time: 0.0542 (0.0542)  evaluator_time: 0.0022 (0.0022)  time: 0.2684  data: 0.2113  max mem: 4304\n",
      "Test:  [ 100/2000]  eta: 0:01:36  model_time: 0.0436 (0.0441)  evaluator_time: 0.0007 (0.0026)  time: 0.0469  data: 0.0013  max mem: 4304\n",
      "Test:  [ 200/2000]  eta: 0:01:27  model_time: 0.0436 (0.0439)  evaluator_time: 0.0007 (0.0021)  time: 0.0473  data: 0.0013  max mem: 4304\n",
      "Test:  [ 300/2000]  eta: 0:01:21  model_time: 0.0422 (0.0435)  evaluator_time: 0.0007 (0.0019)  time: 0.0452  data: 0.0013  max mem: 4304\n",
      "Test:  [ 400/2000]  eta: 0:01:15  model_time: 0.0422 (0.0432)  evaluator_time: 0.0008 (0.0018)  time: 0.0459  data: 0.0013  max mem: 4304\n",
      "Test:  [ 500/2000]  eta: 0:01:10  model_time: 0.0422 (0.0430)  evaluator_time: 0.0009 (0.0018)  time: 0.0465  data: 0.0013  max mem: 4304\n",
      "Test:  [ 600/2000]  eta: 0:01:05  model_time: 0.0422 (0.0429)  evaluator_time: 0.0006 (0.0018)  time: 0.0449  data: 0.0013  max mem: 4304\n",
      "Test:  [ 700/2000]  eta: 0:01:00  model_time: 0.0425 (0.0428)  evaluator_time: 0.0008 (0.0017)  time: 0.0463  data: 0.0013  max mem: 4304\n",
      "Test:  [ 800/2000]  eta: 0:00:55  model_time: 0.0422 (0.0428)  evaluator_time: 0.0007 (0.0017)  time: 0.0452  data: 0.0012  max mem: 4304\n",
      "Test:  [ 900/2000]  eta: 0:00:51  model_time: 0.0423 (0.0427)  evaluator_time: 0.0009 (0.0017)  time: 0.0460  data: 0.0013  max mem: 4304\n",
      "Test:  [1000/2000]  eta: 0:00:46  model_time: 0.0410 (0.0426)  evaluator_time: 0.0006 (0.0016)  time: 0.0434  data: 0.0012  max mem: 4304\n",
      "Test:  [1100/2000]  eta: 0:00:41  model_time: 0.0418 (0.0424)  evaluator_time: 0.0007 (0.0017)  time: 0.0445  data: 0.0012  max mem: 4304\n",
      "Test:  [1200/2000]  eta: 0:00:36  model_time: 0.0411 (0.0423)  evaluator_time: 0.0006 (0.0017)  time: 0.0444  data: 0.0013  max mem: 4304\n",
      "Test:  [1300/2000]  eta: 0:00:32  model_time: 0.0375 (0.0422)  evaluator_time: 0.0007 (0.0017)  time: 0.0422  data: 0.0013  max mem: 4304\n",
      "Test:  [1400/2000]  eta: 0:00:27  model_time: 0.0374 (0.0420)  evaluator_time: 0.0006 (0.0016)  time: 0.0417  data: 0.0013  max mem: 4304\n",
      "Test:  [1500/2000]  eta: 0:00:22  model_time: 0.0375 (0.0418)  evaluator_time: 0.0006 (0.0016)  time: 0.0421  data: 0.0013  max mem: 4304\n",
      "Test:  [1600/2000]  eta: 0:00:18  model_time: 0.0380 (0.0417)  evaluator_time: 0.0006 (0.0016)  time: 0.0427  data: 0.0012  max mem: 4304\n",
      "Test:  [1700/2000]  eta: 0:00:13  model_time: 0.0374 (0.0415)  evaluator_time: 0.0007 (0.0016)  time: 0.0422  data: 0.0012  max mem: 4304\n",
      "Test:  [1800/2000]  eta: 0:00:08  model_time: 0.0375 (0.0414)  evaluator_time: 0.0009 (0.0016)  time: 0.0436  data: 0.0013  max mem: 4304\n",
      "Test:  [1900/2000]  eta: 0:00:04  model_time: 0.0376 (0.0413)  evaluator_time: 0.0007 (0.0016)  time: 0.0433  data: 0.0012  max mem: 4304\n",
      "Test:  [1999/2000]  eta: 0:00:00  model_time: 0.0376 (0.0412)  evaluator_time: 0.0011 (0.0016)  time: 0.0436  data: 0.0013  max mem: 4304\n",
      "Test: Total time: 0:01:29 (0.0448 s / it)\n",
      "Averaged stats: model_time: 0.0376 (0.0412)  evaluator_time: 0.0011 (0.0016)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.45s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.530\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581\n"
     ]
    }
   ],
   "source": [
    "from detection_tools.engine import train_one_epoch, evaluate\n",
    "\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "dataset_train = MyDetectionDataset(\n",
    "    \"data/data.csv\",\n",
    "    transforms=get_transform(train=True),\n",
    "    tag=\"train\"\n",
    ")\n",
    "dataset_val = MyDetectionDataset(\n",
    "    \"data/data.csv\",\n",
    "    transforms=get_transform(train=False),\n",
    "    tag=\"val\"\n",
    ")\n",
    "\n",
    "# define training and validation data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "# build the model\n",
    "num_classes = len(label_mapping) + 1  # 0: background, 1...N: classes\n",
    "model = get_fasterrcnn_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "# let's train it just for 2 epochs\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(\n",
    "        model, optimizer, data_loader,\n",
    "        device, epoch, print_freq=100\n",
    "    )\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, val_loader, device=device)\n",
    "\n",
    "# Save the model\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    os.path.join(\"checkpoints\", \"model.pth\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model = get_fasterrcnn_model(num_classes)\n",
    "model.load_state_dict(\n",
    "    torch.load(os.path.join(\"checkpoints\", \"model.pth\"))\n",
    ")\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2968it [01:22, 36.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_test = MyDetectionDataset(\n",
    "    \"data/data.csv\",\n",
    "    transforms=get_transform(train=False),\n",
    "    tag=\"test\"\n",
    ")\n",
    "\n",
    "\n",
    "res_dir = \"results/faster_rcnn\"\n",
    "os.makedirs(res_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, img, target) in tqdm(enumerate(dataset_test)):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img.to(device)])\n",
    "    # Apply NMS:\n",
    "    # note that predicted boxes are in xyxy format\n",
    "    # (as expected for NMS)\n",
    "    keep = torchvision.ops.nms(\n",
    "        prediction[0][\"boxes\"],\n",
    "        prediction[0][\"scores\"],\n",
    "        iou_threshold=0.5\n",
    "    )\n",
    "    prediction[0][\"boxes\"] = prediction[0][\"boxes\"][keep]\n",
    "    prediction[0][\"labels\"] = prediction[0][\"labels\"][keep]\n",
    "    prediction[0][\"scores\"] = prediction[0][\"scores\"][keep]\n",
    "\n",
    "    # save prediction as json\n",
    "    filename = os.path.basename(img_path)\n",
    "    with open(os.path.join(res_dir, filename.replace(\".jpg\", \".json\")), \"wt\") as f:\n",
    "        res = {key: val.cpu().numpy().tolist() for key, val in prediction[0].items()}\n",
    "        res[\"image_path\"] = img_path\n",
    "        json.dump(res, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samples_count': 2968,\n",
       " 'samples_bytes': 19199380,\n",
       " 'samples_size': '18.3MB',\n",
       " 'total_bytes': 19199380,\n",
       " 'total_size': '18.3MB'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "from PIL import Image\n",
    "\n",
    "ds_name = \"faster_rcnn_predictions\"\n",
    "if ds_name in fo.list_datasets():\n",
    "    fo.delete_dataset(ds_name)\n",
    "\n",
    "dataset = fo.Dataset(name=ds_name)\n",
    "\n",
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df_test = df[df[\"tag\"] == \"test\"]\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    sample = fo.Sample(filepath=row[\"imagepath\"])\n",
    "\n",
    "    filename = os.path.basename(row[\"imagepath\"])\n",
    "    img = Image.open(row[\"imagepath\"])\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    gt_file = row[\"labelpath\"]\n",
    "    with open(gt_file, \"rt\") as f:\n",
    "        gt = json.load(f)\n",
    "\n",
    "    # Add ground truth\n",
    "    list_gt = []\n",
    "    for obj in gt:\n",
    "        label = obj[\"label\"]\n",
    "        box = [\n",
    "            obj[\"x\"] / img_width, obj[\"y\"] / img_height,\n",
    "            obj[\"width\"] / img_width, obj[\"height\"] / img_height\n",
    "        ]\n",
    "        detection = fo.Detection(\n",
    "            label=label,\n",
    "            bounding_box=box\n",
    "        )\n",
    "        list_gt.append(detection)\n",
    "    sample[\"ground_truth\"] = fo.Detections(detections=list_gt)\n",
    "\n",
    "    # Add predictions\n",
    "    pred_file = os.path.join(res_dir, filename.replace(\".jpg\", \".json\"))\n",
    "    pred = json.load(open(pred_file, \"rt\"))\n",
    "\n",
    "    labels = pred[\"labels\"]\n",
    "    boxes_xyxy = pred[\"boxes\"]\n",
    "    scores = pred[\"scores\"]\n",
    "    # convert box format from xyxy to xywh\n",
    "    boxes_xywh = torchvision.ops.box_convert(\n",
    "        torch.tensor(boxes_xyxy),\n",
    "        in_fmt=\"xyxy\",\n",
    "        out_fmt=\"xywh\"\n",
    "    )\n",
    "\n",
    "    list_detections = []\n",
    "    for label, box, score in zip(labels, boxes_xywh, scores):\n",
    "        box = [\n",
    "            box[0] / img_width, box[1] / img_height,\n",
    "            box[2] / img_width, box[3] / img_height\n",
    "        ]\n",
    "        label = list(label_mapping.keys())[list(label_mapping.values()).index(label)]\n",
    "        detection = fo.Detection(label=label, bounding_box=box, confidence=score)\n",
    "        list_detections.append(detection)\n",
    "\n",
    "    sample[\"faster_rcnn\"] = fo.Detections(detections=list_detections)\n",
    "    dataset.add_sample(sample)\n",
    "\n",
    "dataset.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset:          faster_rcnn_predictions\n",
       "Media type:       image\n",
       "Num samples:      2968\n",
       "Selected samples: 0\n",
       "Selected labels:  0\n",
       "Session URL:      http://localhost:5151/\n",
       "View stages:\n",
       "    1. FilterLabels(field='faster_rcnn', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import fiftyone as fo\n",
    "#ds_name = \"faster_rcnn_predictions\"\n",
    "#dataset = fo.load_dataset(ds_name)\n",
    "\n",
    "\n",
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only contains detections with confidence >= 0.75\n",
    "high_conf_view = dataset.filter_labels(\n",
    "    \"faster_rcnn\", F(\"confidence\") > 0.75, only_matches=False\n",
    ")\n",
    "\n",
    "session = fo.launch_app(high_conf_view, auto=False)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████| 2968/2968 [16.5s elapsed, 0s remaining, 206.8 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 2968/2968 [10.0s elapsed, 0s remaining, 331.2 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = high_conf_view.evaluate_detections(\n",
    "    \"faster_rcnn\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      person       0.68      0.67      0.67     11004\n",
      "         car       0.75      0.40      0.52      1932\n",
      "     bicycle       0.73      0.19      0.31       316\n",
      "  motorcycle       0.95      0.19      0.31       371\n",
      "         bus       0.75      0.55      0.63       285\n",
      "       truck       0.69      0.12      0.21       415\n",
      "\n",
      "   micro avg       0.68      0.60      0.64     14323\n",
      "   macro avg       0.76      0.35      0.44     14323\n",
      "weighted avg       0.70      0.60      0.62     14323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "if len(label_mapping) > 10:\n",
    "    counts = dataset.count_values(\"ground_truth.detections.label\")\n",
    "    classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "else:\n",
    "    classes_top10 = list(label_mapping.keys())\n",
    "    \n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objrecognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
